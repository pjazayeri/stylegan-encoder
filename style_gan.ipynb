{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "style_gan.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pjazayeri/stylegan-encoder/blob/master/style_gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIabOSPhYgTD",
        "colab_type": "text"
      },
      "source": [
        "# Generating High Rez GAN Faces with Google CoLab\n",
        "\n",
        "This notebook demonstrates how to run [NVidia StyleGAN](https://github.com/NVlabs/stylegan) inside of a Google CoLab notebook.  I suggest you use this to generate GAN faces from a pretrained model.  If you try to train your own, you will run into compute limitations of Google CoLab.\n",
        "\n",
        "Make sure to run this code on a GPU instance.  GPU is assumed.\n",
        "\n",
        "# Instructions\n",
        "\n",
        "First, map your G-Drive, this is where your GANs will be written to."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kv7PBBU7kOkD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True) #Get access to google drive using personal account (pj1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6hxfZgyJpVA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rm  -r stylegan-encoder #Remove the repo if it exists"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "te61MEsUS_ts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/pjazayeri/stylegan-encoder.git #clone the repo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaFXI2RMhmly",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.insert(0, \"/content/stylegan-encoder\")\n",
        "\n",
        "import dnnlib #verify that the repo was cloned"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UuNkX4ZTTvP",
        "colab_type": "code",
        "outputId": "fb5630f2-d9b0-4485-b258-ff22035f332b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls /content/drive/My\\ Drive/raw_images/ #put raw images in the /raw_images folder"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "aryana2.png  aryana.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4ven_tPTY0y",
        "colab_type": "code",
        "outputId": "500ef21a-19ce-4f08-ba3c-13a71c737c3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!python /content/stylegan-encoder/align_images.py /content/drive/My\\ Drive/raw_images/ /content/drive/My\\ Drive/aligned_images/ #use align_images.py to crop and align raw images"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpFUFyro5N0_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls /content/drive/My\\ Drive/aligned_images #check which imaged have been aligned to just detected faces."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsW5VzERba9k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python /content/stylegan-encoder/encode_images.py /content/drive/My\\ Drive/aligned_images/ /content/drive/My\\ Drive/generated_images/ /content/drive/My\\ Drive/latent_representations/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zARjPp4rY6vc",
        "colab_type": "text"
      },
      "source": [
        "Add the Stylegan folder to Python so that you can import it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxmjqpxdZFkj",
        "colab_type": "text"
      },
      "source": [
        "The code below is baed on code from NVidia.  This actually generates your images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9zjb3KbrvNY",
        "colab_type": "code",
        "outputId": "522ad631-5771-412b-cbe4-efaac5f03330",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "# Copyright (c) 2019, NVIDIA CORPORATION. All rights reserved.\n",
        "#\n",
        "# This work is licensed under the Creative Commons Attribution-NonCommercial\n",
        "# 4.0 International License. To view a copy of this license, visit\n",
        "# http://creativecommons.org/licenses/by-nc/4.0/ or send a letter to\n",
        "# Creative Commons, PO Box 1866, Mountain View, CA 94042, USA.\n",
        "\n",
        "\"\"\"Minimal script for reproducing the figures of the StyleGAN paper using pre-trained generators.\"\"\"\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import dnnlib\n",
        "import dnnlib.tflib as tflib\n",
        "import config\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "# Helpers for loading and using pre-trained generators.\n",
        "\n",
        "url_ffhq        = 'https://drive.google.com/uc?id=1MEGjdvVpUsu1jB4zrXZN7Y4kBBOzizDQ' # karras2019stylegan-ffhq-1024x1024.pkl\n",
        "url_celebahq    = 'https://drive.google.com/uc?id=1MGqJl28pN4t7SAtSrPdSRJSQJqahkzUf' # karras2019stylegan-celebahq-1024x1024.pkl\n",
        "url_bedrooms    = 'https://drive.google.com/uc?id=1MOSKeGF0FJcivpBI7s63V9YHloUTORiF' # karras2019stylegan-bedrooms-256x256.pkl\n",
        "url_cars        = 'https://drive.google.com/uc?id=1MJ6iCfNtMIRicihwRorsM3b7mmtmK9c3' # karras2019stylegan-cars-512x384.pkl\n",
        "url_cats        = 'https://drive.google.com/uc?id=1MQywl0FNt6lHu8E_EUqnRbviagS7fbiJ' # karras2019stylegan-cats-256x256.pkl\n",
        "\n",
        "synthesis_kwargs = dict(output_transform=dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True), minibatch_size=8)\n",
        "\n",
        "_Gs_cache = dict()\n",
        "\n",
        "def load_Gs(url):\n",
        "    if url not in _Gs_cache:\n",
        "        with dnnlib.util.open_url(url, cache_dir=config.cache_dir) as f:\n",
        "            _G, _D, Gs = pickle.load(f)\n",
        "        _Gs_cache[url] = Gs\n",
        "    return _Gs_cache[url]\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "# Figures 2, 3, 10, 11, 12: Multi-resolution grid of uncurated result images.\n",
        "\n",
        "def draw_uncurated_result_figure(png, Gs, cx, cy, cw, ch, rows, lods, seed):\n",
        "    print(png)\n",
        "    latents = np.random.RandomState(seed).randn(sum(rows * 2**lod for lod in lods), Gs.input_shape[1])\n",
        "    images = Gs.run(latents, None, **synthesis_kwargs) # [seed, y, x, rgb]\n",
        "\n",
        "    canvas = PIL.Image.new('RGB', (sum(cw // 2**lod for lod in lods), ch * rows), 'white')\n",
        "    image_iter = iter(list(images))\n",
        "    for col, lod in enumerate(lods):\n",
        "        for row in range(rows * 2**lod):\n",
        "            image = PIL.Image.fromarray(next(image_iter), 'RGB')\n",
        "            image = image.crop((cx, cy, cx + cw, cy + ch))\n",
        "            image = image.resize((cw // 2**lod, ch // 2**lod), PIL.Image.ANTIALIAS)\n",
        "            canvas.paste(image, (sum(cw // 2**lod for lod in lods[:col]), row * ch // 2**lod))\n",
        "    canvas.save(png)\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "# Figure 3: Style mixing.\n",
        "\n",
        "def draw_style_mixing_figure(png, Gs, w, h, src_seeds, dst_seeds, style_ranges,latents):\n",
        "    print(png)\n",
        "    src_latents = np.stack(np.random.RandomState(seed).randn(Gs.input_shape[1]) for seed in src_seeds)\n",
        "    dst_latents = np.stack(np.random.RandomState(seed).randn(Gs.input_shape[1]) for seed in dst_seeds)\n",
        "    \n",
        "    #print([range(0,4)]*3+[range(4,8)]*2+[range(8,18)])\n",
        "    #print(src_latents)\n",
        "    \n",
        "    dlatents = np.stack(latents)\n",
        "    \n",
        "    print(src_latents.shape)\n",
        "    \n",
        "    src_dlatents = dlatents #Gs.components.mapping.run(src_latents, None) # [seed, layer, component]\n",
        "    dst_dlatents = dlatents #Gs.components.mapping.run(dst_latents, None) # [seed, layer, component]\n",
        "    \n",
        "    print(src_dlatents.shape)\n",
        "    \n",
        "    src_images = Gs.components.synthesis.run(src_dlatents, randomize_noise=False, **synthesis_kwargs)\n",
        "    dst_images = Gs.components.synthesis.run(dst_dlatents, randomize_noise=False, **synthesis_kwargs)\n",
        "\n",
        "    canvas = PIL.Image.new('RGB', (w * (len(dlatents) + 1), h * (len(dlatents) + 1)), 'white')\n",
        "    for col, src_image in enumerate(list(src_images)):\n",
        "        canvas.paste(PIL.Image.fromarray(src_image, 'RGB'), ((col + 1) * w, 0))\n",
        "    for row, dst_image in enumerate(list(dst_images)):\n",
        "        canvas.paste(PIL.Image.fromarray(dst_image, 'RGB'), (0, (row + 1) * h))\n",
        "        row_dlatents = np.stack([dst_dlatents[row]] * len(dlatents))\n",
        "        row_dlatents[:, style_ranges[row]] = src_dlatents[:, style_ranges[row]]\n",
        "        row_images = Gs.components.synthesis.run(row_dlatents, randomize_noise=False, **synthesis_kwargs)\n",
        "        for col, image in enumerate(list(row_images)):\n",
        "            canvas.paste(PIL.Image.fromarray(image, 'RGB'), ((col + 1) * w, (row + 1) * h))\n",
        "    canvas.save(png)\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "# Main program.\n",
        "\n",
        "def main():\n",
        "    tflib.init_tf()\n",
        "    os.makedirs(config.result_dir, exist_ok=True)\n",
        "    neema = np.load(os.path.join(config.result_dir, f'/content/drive/My Drive/latent_representations/neema_01.npy'))\n",
        "    neema01 = np.load(os.path.join(config.result_dir, f'/content/drive/My Drive/latent_representations/1_01.npy'))\n",
        "    alex = np.load(os.path.join(config.result_dir, f'/content/drive/My Drive/latent_representations/2_01.npy'))\n",
        "    herosh = np.load(os.path.join(config.result_dir, f'/content/drive/My Drive/latent_representations/3_01.npy'))\n",
        "    eman = np.load(os.path.join(config.result_dir, f'/content/drive/My Drive/latent_representations/4_01.npy'))\n",
        "    nk = np.load(os.path.join(config.result_dir, f'/content/drive/My Drive/latent_representations/nk_01.npy'))\n",
        "    hilda = np.load(os.path.join(config.result_dir, f'/content/drive/My Drive/latent_representations/hilda_01.npy'))\n",
        "    sarah = np.load(os.path.join(config.result_dir, f'/content/drive/My Drive/latent_representations/sarah_01.npy'))\n",
        "    neda = np.load(os.path.join(config.result_dir, f'/content/drive/My Drive/latent_representations/neda_01.npy'))\n",
        "\n",
        "    arg_latents = [neema,neda,hilda,sarah]\n",
        "\n",
        "    #draw_uncurated_result_figure(os.path.join(config.result_dir, 'figure02-uncurated-ffhq.png'), load_Gs(url_ffhq), cx=0, cy=0, cw=1024, ch=1024, rows=3, lods=[0,1,2,2,3,3], seed=5)\n",
        "    draw_style_mixing_figure(os.path.join(config.result_dir, f'/content/drive/My Drive/images/figure03-style-mixing.png'), load_Gs(url_ffhq), w=1024, h=1024, src_seeds=[123,701,687,615], dst_seeds=[888,829,1898,1733,1614], style_ranges=[range(0,4)]*3+[range(4,8)]*2+[range(8,18)], latents=arg_latents)\n",
        "    #draw_noise_detail_figure(os.path.join(config.result_dir, 'figure04-noise-detail.png'), load_Gs(url_ffhq), w=1024, h=1024, num_samples=100, seeds=[1157,1012])\n",
        "    #draw_noise_components_figure(os.path.join(config.result_dir, 'figure05-noise-components.png'), load_Gs(url_ffhq), w=1024, h=1024, seeds=[1967,1555], noise_ranges=[range(0, 18), range(0, 0), range(8, 18), range(0, 8)], flips=[1])\n",
        "    #draw_truncation_trick_figure(os.path.join(config.result_dir, 'figure08-truncation-trick.png'), load_Gs(url_ffhq), w=1024, h=1024, seeds=[91,388], psis=[1, 0.7, 0.5, 0, -0.5, -1])\n",
        "    #draw_uncurated_result_figure(os.path.join(config.result_dir, 'figure10-uncurated-bedrooms.png'), load_Gs(url_bedrooms), cx=0, cy=0, cw=256, ch=256, rows=5, lods=[0,0,1,1,2,2,2], seed=0)\n",
        "    #draw_uncurated_result_figure(os.path.join(config.result_dir, 'figure11-uncurated-cars.png'), load_Gs(url_cars), cx=0, cy=64, cw=512, ch=384, rows=4, lods=[0,1,2,2,3,3], seed=2)\n",
        "    #draw_uncurated_result_figure(os.path.join(config.result_dir, 'figure12-uncurated-cats.png'), load_Gs(url_cats), cx=0, cy=0, cw=256, ch=256, rows=5, lods=[0,0,1,1,2,2,2], seed=1)\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "#----------------------------------------------------------------------------\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "/content/drive/My Drive/images/figure03-style-mixing.png\n",
            "(4, 512)\n",
            "(4, 18, 512)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:55: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:56: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzqJGX1Gj_fn",
        "colab_type": "code",
        "outputId": "3571eecf-fa70-426b-f65a-136c9a39196e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!ls /content/drive/My\\ Drive/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'Colab Notebooks'\t\t\t\t  example.png\n",
            "'Copy of karras2019stylegan-ffhq-1024x1024.pkl'   projects\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}