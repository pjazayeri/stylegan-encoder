{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "style_gan.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pjazayeri/stylegan-encoder/blob/master/style_gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIabOSPhYgTD",
        "colab_type": "text"
      },
      "source": [
        "# Generating High Rez GAN Faces with Google CoLab\n",
        "\n",
        "This notebook demonstrates how to run [NVidia StyleGAN](https://github.com/NVlabs/stylegan) inside of a Google CoLab notebook.  I suggest you use this to generate GAN faces from a pretrained model.  If you try to train your own, you will run into compute limitations of Google CoLab.\n",
        "\n",
        "Make sure to run this code on a GPU instance.  GPU is assumed.\n",
        "\n",
        "# Instructions\n",
        "\n",
        "First, map your G-Drive, this is where your GANs will be written to."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kv7PBBU7kOkD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive', force_remount=True) #Get access to google drive using personal account (pj1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6hxfZgyJpVA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rm  -r stylegan-encoder #Remove the repo if it exists"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "te61MEsUS_ts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/pjazayeri/stylegan-encoder.git #clone the repo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaFXI2RMhmly",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.insert(0, \"/content/stylegan-encoder\") #Add the Stylegan folder to Python so that you can import it.\n",
        "\n",
        "import dnnlib #verify that the repo was cloned"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UuNkX4ZTTvP",
        "colab_type": "code",
        "outputId": "6d5e6dd9-b1be-4476-f98a-d8aad8e347d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls /content/drive/My\\ Drive/raw_images/ #put raw images in the /raw_images folder"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ls: cannot access '/content/drive/My Drive/raw_images/': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4ven_tPTY0y",
        "colab_type": "code",
        "outputId": "6fcd83f8-ab25-46d5-c52a-3eacfc79ff76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!python /content/stylegan-encoder/align_images.py /content/drive/My\\ Drive/raw_images/ /content/drive/My\\ Drive/aligned_images/ #use align_images.py to crop and align raw images"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpFUFyro5N0_",
        "colab_type": "code",
        "outputId": "9ba8e2c8-1d09-499a-edfa-abf1e10dcf31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls /content/drive/My\\ Drive/aligned_images #check which imaged have been aligned to just detected faces."
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ls: cannot access '/content/drive/My Drive/aligned_images': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsW5VzERba9k",
        "colab_type": "code",
        "outputId": "d7504fbb-a6b5-4007-d5b0-01bbf6701774",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!python /content/stylegan-encoder/encode_images.py /content/drive/My\\ Drive/aligned_images/ /content/drive/My\\ Drive/generated_images/ /content/drive/My\\ Drive/latent_representations/ #Derive the images' latent representations and regenerate the original images as a sanitycheck"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python3: can't open file '/content/stylegan-encoder/encode_images.py': [Errno 2] No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxmjqpxdZFkj",
        "colab_type": "text"
      },
      "source": [
        "The code below is based on code from NVidia.  This actually generates your images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9zjb3KbrvNY",
        "colab_type": "code",
        "outputId": "d48e68c2-3554-4559-978f-498aefb9b51f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "source": [
        "# Copyright (c) 2019, NVIDIA CORPORATION. All rights reserved.\n",
        "#\n",
        "# This work is licensed under the Creative Commons Attribution-NonCommercial\n",
        "# 4.0 International License. To view a copy of this license, visit\n",
        "# http://creativecommons.org/licenses/by-nc/4.0/ or send a letter to\n",
        "# Creative Commons, PO Box 1866, Mountain View, CA 94042, USA.\n",
        "\n",
        "\"\"\"Minimal script for reproducing the figures of the StyleGAN paper using pre-trained generators.\"\"\"\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import dnnlib\n",
        "import dnnlib.tflib as tflib\n",
        "import config\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "# Helpers for loading and using pre-trained generators.\n",
        "\n",
        "url_ffhq        = 'https://drive.google.com/uc?id=1MEGjdvVpUsu1jB4zrXZN7Y4kBBOzizDQ' # karras2019stylegan-ffhq-1024x1024.pkl\n",
        "\n",
        "synthesis_kwargs = dict(output_transform=dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True), minibatch_size=8)\n",
        "\n",
        "_Gs_cache = dict()\n",
        "\n",
        "def load_Gs(url):\n",
        "    if url not in _Gs_cache:\n",
        "        with dnnlib.util.open_url(url, cache_dir=config.cache_dir) as f:\n",
        "            _G, _D, Gs = pickle.load(f)\n",
        "        _Gs_cache[url] = Gs\n",
        "    return _Gs_cache[url]\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "# Figures 2, 3, 10, 11, 12: Multi-resolution grid of uncurated result images.\n",
        "\n",
        "def draw_uncurated_result_figure(png, Gs, cx, cy, cw, ch, rows, lods, seed):\n",
        "    print(png)\n",
        "    latents = np.random.RandomState(seed).randn(sum(rows * 2**lod for lod in lods), Gs.input_shape[1])\n",
        "    images = Gs.run(latents, None, **synthesis_kwargs) # [seed, y, x, rgb]\n",
        "\n",
        "    canvas = PIL.Image.new('RGB', (sum(cw // 2**lod for lod in lods), ch * rows), 'white')\n",
        "    image_iter = iter(list(images))\n",
        "    for col, lod in enumerate(lods):\n",
        "        for row in range(rows * 2**lod):\n",
        "            image = PIL.Image.fromarray(next(image_iter), 'RGB')\n",
        "            image = image.crop((cx, cy, cx + cw, cy + ch))\n",
        "            image = image.resize((cw // 2**lod, ch // 2**lod), PIL.Image.ANTIALIAS)\n",
        "            canvas.paste(image, (sum(cw // 2**lod for lod in lods[:col]), row * ch // 2**lod))\n",
        "    canvas.save(png)\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "# Figure 3: Style mixing.\n",
        "\n",
        "def draw_style_mixing_figure(png, Gs, w, h, src_seeds, dst_seeds, style_ranges,latents):\n",
        "    print(png)\n",
        "    src_latents = np.stack(np.random.RandomState(seed).randn(Gs.input_shape[1]) for seed in src_seeds)\n",
        "    dst_latents = np.stack(np.random.RandomState(seed).randn(Gs.input_shape[1]) for seed in dst_seeds)\n",
        "    \n",
        "    #print([range(0,4)]*3+[range(4,8)]*2+[range(8,18)])\n",
        "    #print(src_latents)\n",
        "    \n",
        "    dlatents = np.stack(latents)\n",
        "    \n",
        "    print(src_latents.shape)\n",
        "    \n",
        "    src_dlatents = dlatents #Gs.components.mapping.run(src_latents, None) # [seed, layer, component]\n",
        "    dst_dlatents = dlatents #Gs.components.mapping.run(dst_latents, None) # [seed, layer, component]\n",
        "    \n",
        "    print(src_dlatents.shape)\n",
        "    \n",
        "    src_images = Gs.components.synthesis.run(src_dlatents, randomize_noise=False, **synthesis_kwargs)\n",
        "    dst_images = Gs.components.synthesis.run(dst_dlatents, randomize_noise=False, **synthesis_kwargs)\n",
        "\n",
        "    canvas = PIL.Image.new('RGB', (w * (len(dlatents) + 1), h * (len(dlatents) + 1)), 'white')\n",
        "    for col, src_image in enumerate(list(src_images)):\n",
        "        canvas.paste(PIL.Image.fromarray(src_image, 'RGB'), ((col + 1) * w, 0))\n",
        "    for row, dst_image in enumerate(list(dst_images)):\n",
        "        canvas.paste(PIL.Image.fromarray(dst_image, 'RGB'), (0, (row + 1) * h))\n",
        "        row_dlatents = np.stack([dst_dlatents[row]] * len(dlatents))\n",
        "        row_dlatents[:, style_ranges[row]] = src_dlatents[:, style_ranges[row]]\n",
        "        row_images = Gs.components.synthesis.run(row_dlatents, randomize_noise=False, **synthesis_kwargs)\n",
        "        for col, image in enumerate(list(row_images)):\n",
        "            canvas.paste(PIL.Image.fromarray(image, 'RGB'), ((col + 1) * w, (row + 1) * h))\n",
        "    canvas.save(png)\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "# Main program.\n",
        "\n",
        "def main():\n",
        "    tflib.init_tf()\n",
        "    os.makedirs(config.result_dir, exist_ok=True)\n",
        "    neema = np.load(os.path.join(config.result_dir, f'/content/drive/My Drive/latent_representations/neema_01.npy'))\n",
        "    neema01 = np.load(os.path.join(config.result_dir, f'/content/drive/My Drive/latent_representations/1_01.npy'))\n",
        "    alex = np.load(os.path.join(config.result_dir, f'/content/drive/My Drive/latent_representations/2_01.npy'))\n",
        "    herosh = np.load(os.path.join(config.result_dir, f'/content/drive/My Drive/latent_representations/3_01.npy'))\n",
        "    eman = np.load(os.path.join(config.result_dir, f'/content/drive/My Drive/latent_representations/4_01.npy'))\n",
        "    nk = np.load(os.path.join(config.result_dir, f'/content/drive/My Drive/latent_representations/nk_01.npy'))\n",
        "    hilda = np.load(os.path.join(config.result_dir, f'/content/drive/My Drive/latent_representations/hilda_01.npy'))\n",
        "    sarah = np.load(os.path.join(config.result_dir, f'/content/drive/My Drive/latent_representations/sarah_01.npy'))\n",
        "    neda = np.load(os.path.join(config.result_dir, f'/content/drive/My Drive/latent_representations/neda_01.npy'))\n",
        "    aryana = np.load(os.path.join(config.result_dir, f'/content/drive/My Drive/latent_representations/aryana_01.npy'))\n",
        "    aryana2 = np.load(os.path.join(config.result_dir, f'/content/drive/My Drive/latent_representations/aryana2_01.npy'))\n",
        "    shawn = np.load(os.path.join(config.result_dir, f'/content/drive/My Drive/latent_representations/shawn_01.npy'))\n",
        "    shawn2 = np.load(os.path.join(config.result_dir, f'/content/drive/My Drive/latent_representations/shawn2_01.npy'))\n",
        "    \n",
        "    arg_latents = [neema,neda,aryana,aryana2,shawn,shawn2]\n",
        "\n",
        "    draw_style_mixing_figure(os.path.join(config.result_dir, f'/content/drive/My Drive/images/figure03-style-mixing.png'), load_Gs(url_ffhq), w=1024, h=1024, src_seeds=[123,701,687,615], dst_seeds=[888,829,1898,1733,1614], style_ranges=[range(0,4)]*3+[range(4,8)]*2+[range(8,18)], latents=arg_latents)\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "#----------------------------------------------------------------------------\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0623 22:06:51.407402 140295260120960 deprecation_wrapper.py:119] From /content/stylegan-encoder/dnnlib/tflib/tfutil.py:34: The name tf.Dimension is deprecated. Please use tf.compat.v1.Dimension instead.\n",
            "\n",
            "W0623 22:06:51.409559 140295260120960 deprecation_wrapper.py:119] From /content/stylegan-encoder/dnnlib/tflib/tfutil.py:74: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0623 22:06:51.410844 140295260120960 deprecation_wrapper.py:119] From /content/stylegan-encoder/dnnlib/tflib/tfutil.py:128: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "W0623 22:06:51.421228 140295260120960 deprecation_wrapper.py:119] From /content/stylegan-encoder/dnnlib/tflib/tfutil.py:97: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0623 22:06:51.422085 140295260120960 deprecation_wrapper.py:119] From /content/stylegan-encoder/dnnlib/tflib/tfutil.py:109: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
            "\n",
            "W0623 22:06:57.140604 140295260120960 deprecation.py:323] From <string>:364: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/images/figure03-style-mixing.png\n",
            "(4, 512)\n",
            "(6, 18, 512)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:51: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:52: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}